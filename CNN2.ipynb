{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "os.chdir(\"C:/Users/yashg/OneDrive/Documents/Covestro Hackathon/ParticleFormationStudentData/StudentData/train_4\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_csv(\"train_scores.csv\")\n",
    "m1=train_data[\"exp1\"]\n",
    "m1=np.array(m1)\n",
    "\n",
    "m2=train_data[\"exp2\"]\n",
    "m2=np.array(m2)\n",
    "\n",
    "m3=train_data[\"exp3\"]\n",
    "m3=np.array(m3)\n",
    "\n",
    "m4=train_data[\"exp4\"]\n",
    "m4=np.array(m4)\n",
    "\n",
    "m5=train_data[\"exp5\"]\n",
    "m5=np.array(m5)\n",
    "\n",
    "m6=train_data[\"exp6\"]\n",
    "m6=np.array(m6)\n",
    "\n",
    "mavg=train_data[\"total_rating\"]\n",
    "mavg=np.array(mavg)\n",
    "\n",
    "r1=np.append(m1,m2)\n",
    "r2=np.append(r1,m3)\n",
    "r3=np.append(r2,m4)\n",
    "r4=np.append(r3,m5)\n",
    "rating=np.append(r3,m6)\n",
    "\n",
    "img=train_data[\"image\"]\n",
    "img1=train_data[\"image\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data,filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(510, 192)\n",
      "(197, 510, 192)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(197, 510, 192, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#img=train_data[\"image\"]\n",
    "#img=np.array(img)\n",
    "\n",
    "list=[]\n",
    "for i in range(197):\n",
    "    im2=cv2.imread(str(img[i])+'.bmp',cv2.IMREAD_GRAYSCALE)\n",
    "    im2=cv2.fastNlMeansDenoising(im2) \n",
    "    #im2 = cv2.GaussianBlur(im2, (2, 2), 0)\n",
    "    #im2 = cv2.bilateralFilter(img,9,75,75)\n",
    "    #im2=cv2.resize(im2,(50,70))\n",
    "    im2=im2/255\n",
    "    im_power_law_transformation = cv2.pow(im2,2.5)\n",
    "    im_power_law_transformation=filters.sobel(im_power_law_transformation)\n",
    "    print(im_power_law_transformation.shape)\n",
    "    list.append(im_power_law_transformation)\n",
    "x=np.array(list)\n",
    "print(x.shape)\n",
    "    \n",
    "x=x.reshape(-1,510,192,1)\n",
    "x=np.array(x)\n",
    "x.shape\n",
    "#o=np.ones()\n",
    "#x2=list.append(1)\n",
    "#np.array(x2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118 samples, validate on 79 samples\n",
      "Epoch 1/2\n",
      "118/118 [==============================] - 152s 1s/sample - loss: 40.0890 - mean_absolute_error: 5.1758 - val_loss: 29.4543 - val_mean_absolute_error: 5.1127\n",
      "Epoch 2/2\n",
      "118/118 [==============================] - 149s 1s/sample - loss: 26.6284 - mean_absolute_error: 4.7992 - val_loss: 29.4543 - val_mean_absolute_error: 5.1127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c22efd1358>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3),input_shape=x.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(126))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])\n",
    "\n",
    "model.fit(x, mavg, batch_size=2, epochs=2, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 100, 100, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=[]\n",
    "for i in range(197):\n",
    "    im2=cv2.imread(str(img[i])+'.bmp',cv2.IMREAD_GRAYSCALE)\n",
    "    im2=cv2.resize(im2,(100,100))\n",
    "    edges = cv2.Canny(image = im2, threshold1 = 200,threshold2 = 255)\n",
    "    p.append(edges)\n",
    "    #print(np.array(p).shape)\n",
    "p=np.array(p)\n",
    "p=p.reshape(-1,100,100,1)\n",
    "p=np.array(p)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a71215a3f518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmavg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3),input_shape=x.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(126))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(p, mavg, batch_size=2, epochs=3, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d5ea40281520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m197\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mim2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.bmp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mim2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfastNlMeansDenoising\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#im2 = cv2.GaussianBlur(im2, (5, 5), 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#im2 = cv2.bilateralFilter(img,9,75,75)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "for i in range(197):\n",
    "    im2=cv2.imread(str(img[i])+'.bmp',cv2.IMREAD_GRAYSCALE)\n",
    "    im2=cv2.fastNlMeansDenoising(im2) \n",
    "    #im2 = cv2.GaussianBlur(im2, (5, 5), 0)\n",
    "    #im2 = cv2.bilateralFilter(img,9,75,75)\n",
    "    im2=cv2.resize(im2,(100,100))\n",
    "    im2=im2/255\n",
    "    im_power_law_transformation = cv2.pow(im2,0.1)\n",
    "#a=np.array(list)\n",
    "#no=a[0]\n",
    "#n2=np.array([a[1],a[2]])\n",
    "#regressor.fit(n2, mavg) \n",
    "#a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img=train_data[\"image\"]\n",
    "#img=np.array(img)\n",
    "\n",
    "list2=[]\n",
    "for i in range(99):\n",
    "    im2=cv2.imread(str(img[i])+'.bmp',cv2.IMREAD_GRAYSCALE)\n",
    "    im2=cv2.fastNlMeansDenoising(im2) \n",
    "    #im2 = cv2.GaussianBlur(im2, (2, 2), 0)\n",
    "    #im2 = cv2.bilateralFilter(img,9,75,75)\n",
    "    #im2=cv2.resize(im2,(50,70))\n",
    "    im2=im2/255\n",
    "    im_power_law_transformation = cv2.pow(im2,2.5)\n",
    "    im_power_law_transformation=filters.sobel(im_power_law_transformation)\n",
    "    print(im_power_law_transformation.shape)\n",
    "    list.append(im_power_law_transformation)\n",
    "x=np.array(list)\n",
    "print(x.shape)\n",
    "    \n",
    "x=x.reshape(-1,510,192,1)\n",
    "x=np.array(x)\n",
    "x.shape\n",
    "#o=np.ones()\n",
    "#x2=list.append(1)\n",
    "#np.array(x2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n",
      "(710, 512)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_8_input to have 4 dimensions, but got array with shape (99, 710, 512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-b87c3e521e71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#x2=x2.reshape(-1,510,192,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[1;32m--> 716\u001b[1;33m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m    717\u001b[0m     return predict_loop(\n\u001b[0;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2471\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2473\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    561\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_8_input to have 4 dimensions, but got array with shape (99, 710, 512)"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/yashg/OneDrive/Documents/Covestro Hackathon/ParticleFormationStudentData/StudentData/test\")\n",
    "test_data=pd.read_csv(\"to_predict.csv\")\n",
    "img3=test_data[\"image\"]\n",
    "img3=np.array(img3)\n",
    "list2=[]\n",
    "for i in range(99):\n",
    "    im4=cv2.imread(str(img3[i])+'.bmp',cv2.IMREAD_GRAYSCALE)\n",
    "    im4=cv2.fastNlMeansDenoising(im4) \n",
    "    #im2 = cv2.GaussianBlur(im2, (2, 2), 0)\n",
    "    #im2 = cv2.bilateralFilter(img,9,75,75)\n",
    "    #im4=cv2.resize(im4,(50,70))\n",
    "    im4=im4/255\n",
    "    im_power_law_transformation = cv2.pow(im4,2.5)\n",
    "    im_power_law_transformation=filters.sobel(im_power_law_transformation)\n",
    "    print(im_power_law_transformation.shape)\n",
    "    list2.append(im_power_law_transformation)\n",
    "#x=np.array(list2)\n",
    "#print(x.shape)\n",
    "#x2=np.array(list2)  \n",
    "\n",
    "#x2=x2.reshape(-1,510,192,1)\n",
    "y=model.predict(x2,batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1329997 ],\n",
       "       [1.2195442 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.9761904 ],\n",
       "       [0.        ],\n",
       "       [0.2611224 ],\n",
       "       [0.        ],\n",
       "       [0.33558285],\n",
       "       [0.        ],\n",
       "       [4.988049  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [3.2638197 ],\n",
       "       [2.6103377 ],\n",
       "       [0.        ],\n",
       "       [3.7405438 ],\n",
       "       [2.3350654 ],\n",
       "       [1.137533  ],\n",
       "       [3.6445396 ],\n",
       "       [1.4779798 ],\n",
       "       [0.        ],\n",
       "       [2.0634792 ],\n",
       "       [1.5953526 ],\n",
       "       [0.        ],\n",
       "       [3.6809127 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [2.434364  ],\n",
       "       [0.7694712 ],\n",
       "       [0.716406  ],\n",
       "       [1.2500508 ],\n",
       "       [3.6740944 ],\n",
       "       [0.4365601 ],\n",
       "       [0.        ],\n",
       "       [1.4615262 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [2.898465  ],\n",
       "       [0.829118  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [3.0683713 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [3.1224852 ],\n",
       "       [0.        ],\n",
       "       [2.3333611 ],\n",
       "       [1.0117021 ],\n",
       "       [0.        ],\n",
       "       [3.6132998 ],\n",
       "       [0.        ],\n",
       "       [3.9804006 ],\n",
       "       [2.3395944 ],\n",
       "       [0.86790884],\n",
       "       [0.        ],\n",
       "       [3.2362652 ],\n",
       "       [0.        ],\n",
       "       [3.1244226 ],\n",
       "       [1.1968347 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [2.795557  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.333614  ],\n",
       "       [0.2932119 ],\n",
       "       [0.        ],\n",
       "       [2.1889148 ],\n",
       "       [0.68930256],\n",
       "       [0.        ],\n",
       "       [0.7886288 ],\n",
       "       [0.        ],\n",
       "       [4.155353  ],\n",
       "       [2.980516  ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.4991698 ],\n",
       "       [4.1965547 ],\n",
       "       [0.7714551 ],\n",
       "       [3.1148453 ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [3.1161902 ],\n",
       "       [3.3190172 ],\n",
       "       [1.4941043 ],\n",
       "       [3.9873364 ],\n",
       "       [0.        ],\n",
       "       [1.8529667 ],\n",
       "       [0.9890677 ],\n",
       "       [3.006876  ],\n",
       "       [0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y).to_csv('scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The parameter `image` must be a 2-dimensional array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-05f1cea8c410>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msobel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.bmp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\filters\\edges.py\u001b[0m in \u001b[0;36msobel\u001b[1;34m(image, mask)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0medges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msobel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcamera\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \"\"\"\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0massert_nD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msobel_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msobel_v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\skimage\\_shared\\utils.py\u001b[0m in \u001b[0;36massert_nD\u001b[1;34m(array, ndim, arg_name)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_empty_array\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_incorrect_dim\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-or-'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The parameter `image` must be a 2-dimensional array"
     ]
    }
   ],
   "source": [
    "from skimage import data,filters\n",
    "edges = filters.sobel(cv2.imread(str(img[0])+'.bmp',cv2.IMREAD_GRAYSCALE))\n",
    "plt.imshow(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
